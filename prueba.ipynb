{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the agent (VisualAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting litellm\n",
      "  Using cached litellm-1.65.4.post1-py3-none-any.whl\n",
      "Requirement already satisfied: aiohttp in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm) (3.11.14)\n",
      "Requirement already satisfied: click in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm) (8.1.8)\n",
      "Requirement already satisfied: httpx>=0.23.0 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm) (0.27.2)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm) (8.6.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm) (4.23.0)\n",
      "Collecting openai>=1.68.2 (from litellm)\n",
      "  Downloading openai-1.72.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm) (2.10.6)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm) (1.0.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm) (0.9.0)\n",
      "Collecting tokenizers (from litellm)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.23.0->litellm) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.23.0->litellm) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.23.0->litellm) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.23.0->litellm) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.23.0->litellm) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from importlib-metadata>=6.8.0->litellm) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.24.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai>=1.68.2->litellm) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai>=1.68.2->litellm) (0.9.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai>=1.68.2->litellm) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai>=1.68.2->litellm) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3.0.0,>=2.0.0->litellm) (2.27.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken>=0.7.0->litellm) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken>=0.7.0->litellm) (2.32.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm) (1.18.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->litellm) (0.4.6)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers->litellm)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\david\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.3.0)\n",
      "Downloading openai-1.72.0-py3-none-any.whl (643 kB)\n",
      "   ---------------------------------------- 0.0/643.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 643.9/643.9 kB 12.3 MB/s eta 0:00:00\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: fsspec, filelock, huggingface-hub, tokenizers, openai, litellm\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.54.5\n",
      "    Uninstalling openai-1.54.5:\n",
      "      Successfully uninstalled openai-1.54.5\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.3.2 huggingface-hub-0.30.2 litellm-1.65.4.post1 openai-1.72.0 tokenizers-0.21.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip  install litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Base ===\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Phoenix core ===\n",
    "import phoenix as px\n",
    "from phoenix.trace import SpanEvaluations\n",
    "from phoenix.trace.dsl import SpanQuery\n",
    "\n",
    "# === Evaluaciones automáticas ===\n",
    "from phoenix.evals import (\n",
    "    TOOL_CALLING_PROMPT_TEMPLATE,\n",
    "    llm_classify,\n",
    "    PromptTemplate,\n",
    ")\n",
    "\n",
    "\n",
    "# === LLM local (ej. llama.cpp o llamafile) ===\n",
    "#from phoenix.evals.models import \n",
    "\n",
    "# === Extra ===\n",
    "from openinference.instrumentation import suppress_tracing\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OLLAMA_API_BASE']= 'http://localhost:11434'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"evaluating-agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'langgraph.version' from 'C:\\\\Users\\\\david\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\langgraph\\\\version.py'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Attempting to instrument while already instrumented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenTelemetry Tracing Details\n",
      "|  Phoenix Project: evaluating-agent\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: https://app.phoenix.arize.com/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {'api_key': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n",
      "[LangGraph] Starting LangGraph execution with tracing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py\", line 534, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connection.py\", line 516, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py\", line 1395, in getresponse\n",
      "    response.begin()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py\", line 325, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py\", line 286, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py\", line 1314, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py\", line 1166, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\util\\retry.py\", line 474, in increment\n",
      "    raise reraise(type(error), error, _stacktrace)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\util\\util.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py\", line 536, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py\", line 367, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\opentelemetry\\sdk\\trace\\export\\__init__.py\", line 113, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\http\\trace_exporter\\__init__.py\", line 189, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\http\\trace_exporter\\__init__.py\", line 159, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\http\\trace_exporter\\__init__.py\", line 133, in _export\n",
      "    return self._session.post(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='app.phoenix.arize.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elección de herramienta: lookup_sales_data\n",
      "Show me the sales in Nov 2021\n",
      "Elección de herramienta: analyzing_data\n",
      "Elección de herramienta: create_visualization\n",
      "Elección de herramienta: analyzing_data\n",
      "Elección de herramienta: end\n",
      "[LangGraph] LangGraph execution completed\n"
     ]
    }
   ],
   "source": [
    "from utils import run_graph_with_tracing, start_main_span\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from phoenix.evals.models import BaseModel\n",
    "from typing import Optional, Sequence, Union, Any\n",
    "from langchain_ollama import ChatOllama\n",
    "import asyncio'\n",
    "'''\n",
    "\n",
    "from phoenix.evals import llm_classify, TOOL_CALLING_PROMPT_TEMPLATE, PromptTemplate, LiteLLMModel\n",
    "from litellm import completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Correct Phoenix Trace Querying ===\n",
    "from phoenix.trace import SpanEvaluations\n",
    "\n",
    "# Define evaluation queries properly\n",
    "sql_query = (\n",
    "    SpanQuery()\n",
    "    .where(\"name == 'sql_query_exec' and span_kind == 'TOOL'\")\n",
    ").select(\n",
    "    question=\"input.value\",\n",
    "    query_gen=\"output.value\",\n",
    ")\n",
    "\n",
    "analysis_query = (\n",
    "    SpanQuery()\n",
    "    .where(\"name == 'data_analysis' and span_kind == 'TOOL'\")\n",
    ").select(\n",
    "    query=\"input.value\",\n",
    "    response=\"output.value\",\n",
    ")\n",
    "\n",
    "viz_query = (\n",
    "    SpanQuery()\n",
    "    .where(\"name == 'gen_visualization' and span_kind == 'TOOL'\")\n",
    ").select(\n",
    "    input=\"input.value\",\n",
    "    generated_code=\"output.value\",\n",
    ")\n",
    "\n",
    "decide_query = (\n",
    "    SpanQuery()\n",
    "    .where(\"span_kind == 'TOOL' and name == 'decide_tool'\")\n",
    ").select(\n",
    "    question=\"input.value\",\n",
    "    tool_call=\"output.value\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create loop to see multiple times the difference in the \"re-runs\"\n",
    "1. Use multiple type of prompts styles for testing\n",
    "2. Human in the loop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. complete\n",
    "2. How to save a csv file with the output of the traces.\n",
    "3. Try to make a decision based on different branches and parallelization\n",
    "4. cook up a docker container\n",
    "5. Try access with the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LangGraph] Starting LangGraph execution with tracing\n",
      "Elección de herramienta: lookup_sales_data\n",
      "What was the most popular product SKU?\n",
      "Elección de herramienta: analyzing_data\n",
      "Elección de herramienta: lookup_sales_data\n",
      "What was the most popular product SKU?\n",
      "Elección de herramienta: analyzing_data\n",
      "Elección de herramienta: end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  20%|██        | 1/5 [00:16<01:07, 16.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LangGraph] LangGraph execution completed\n",
      "[LangGraph] Starting LangGraph execution with tracing\n",
      "Elección de herramienta: lookup_sales_data\n",
      "What was the total revenue across all stores?\n",
      "Elección de herramienta: analyzing_data\n",
      "Elección de herramienta: analyzing_data\n",
      "Elección de herramienta: end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  40%|████      | 2/5 [00:29<00:42, 14.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LangGraph] LangGraph execution completed\n",
      "[LangGraph] Starting LangGraph execution with tracing\n",
      "Elección de herramienta: lookup_sales_data\n",
      "Which store had the highest sales volume?\n",
      "Elección de herramienta: analyzing_data\n",
      "Elección de herramienta: create_visualization\n",
      "Elección de herramienta: analyzing_data\n",
      "Elección de herramienta: end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  60%|██████    | 3/5 [00:55<00:39, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LangGraph] LangGraph execution completed\n",
      "[LangGraph] Starting LangGraph execution with tracing\n",
      "Elección de herramienta: lookup_sales_data\n",
      "Create a bar chart showing total sales by store\n",
      "Elección de herramienta: create_visualization\n",
      "Elección de herramienta: analyzing_data\n",
      "Elección de herramienta: create_visualization\n",
      "Elección de herramienta: analyzing_data\n",
      "Elección de herramienta: end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  80%|████████  | 4/5 [01:30<00:25, 25.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LangGraph] LangGraph execution completed\n",
      "[LangGraph] Starting LangGraph execution with tracing\n",
      "Elección de herramienta: lookup_sales_data\n",
      "What was the average transaction value?\n",
      "Elección de herramienta: analyzing_data\n",
      "Elección de herramienta: analyzing_data\n",
      "Elección de herramienta: end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions: 100%|██████████| 5/5 [01:38<00:00, 19.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LangGraph] LangGraph execution completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "agent_questions = [\n",
    "    \"What was the most popular product SKU?\",\n",
    "    \"What was the total revenue across all stores?\",\n",
    "    \"Which store had the highest sales volume?\",\n",
    "    \"Create a bar chart showing total sales by store\",\n",
    "    \"What was the average transaction value?\"\n",
    "]\n",
    "\n",
    "for question in tqdm(agent_questions, desc=\"Processing questions\"):\n",
    "    try:\n",
    "        input_state = {\n",
    "            \"prompt\": question,\n",
    "        }\n",
    "        ret = run_graph_with_tracing(input_state)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing question: {question}\")\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts for evaluation of the tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SQL Generation Evaluation ===\n",
    "SQL_EVAL_GEN_PROMPT = \"\"\"\n",
    "SQL Evaluation Prompt:\n",
    "-----------------------\n",
    "You are tasked with determining if the SQL generated appropiately answers a given instruction\n",
    "taking into account its generated query and response.\n",
    "\n",
    "Data:\n",
    "-----\n",
    "- [Instruction]: {question}\n",
    "  This section contains the specific task or problem that the sql query is intended to solve.\n",
    "\n",
    "- [Reference Query]: {query_gen}\n",
    "  This is the sql query submitted for evaluation. Analyze it in the context of the provided\n",
    "  instruction.\n",
    "\n",
    "Evaluation:\n",
    "-----------\n",
    "Your response should be a single word: either \"correct\" or \"incorrect\".\n",
    "You must assume that the db exists and that columns are appropiately named.\n",
    "You must take into account the response as additional information to determine the correctness.\n",
    "\n",
    "- \"correct\" indicates that the sql query correctly solves the instruction.\n",
    "- \"incorrect\" indicates that the sql query correctly does not solve the instruction correctly.\n",
    "\n",
    "Note: Your response should contain only the word \"correct\" or \"incorrect\" with no additional text\n",
    "or characters.\n",
    "\"\"\"\n",
    "\n",
    "# === Data Analysis Evaluation ===\n",
    "CLARITY_LLM_JUDGE_PROMPT = \"\"\"\n",
    "In this task, you will be presented with a query and an answer. Your objective is to evaluate the clarity \n",
    "of the answer in addressing the query. A clear response is one that is precise, coherent, and directly \n",
    "addresses the query without introducing unnecessary complexity or ambiguity. An unclear response is one \n",
    "that is vague, disorganized, or difficult to understand, even if it may be factually correct.\n",
    "\n",
    "Your response should be a single word: either \"clear\" or \"unclear,\" and it should not include any other \n",
    "text or characters. \"clear\" indicates that the answer is well-structured, easy to understand, and \n",
    "appropriately addresses the query. \"unclear\" indicates that some part of the response could be better \n",
    "structured or worded.\n",
    "Please carefully consider the query and answer before determining your response.\n",
    "\n",
    "After analyzing the query and the answer, you must write a detailed explanation of your reasoning to \n",
    "justify why you chose either \"clear\" or \"unclear.\" Avoid stating the final label at the beginning of your \n",
    "explanation. Your reasoning should include specific points about how the answer does or does not meet the \n",
    "criteria for clarity.\n",
    "\n",
    "[BEGIN DATA]\n",
    "Query: {query}\n",
    "Answer: {response}\n",
    "[END DATA]\n",
    "Please analyze the data carefully and provide an explanation followed by your response.\n",
    "\n",
    "EXPLANATION: Provide your reasoning step by step, evaluating the clarity of the answer based on the query.\n",
    "LABEL: \"clear\" or \"unclear\"\n",
    "\"\"\"\n",
    "\n",
    "# === Visualization Evaluation ===\n",
    "VIZ_QUALITY_TEMPLATE = PromptTemplate(\"\"\"\n",
    "Evaluate this visualization configuration:\n",
    "1. Appropriateness of chart type for the data\n",
    "2. Correct mapping of axes\n",
    "3. Clarity of visualization goal\n",
    "\n",
    "Goal: {input}\n",
    "Data Sample: {reference_data}\n",
    "Configuration: {output}\n",
    "\n",
    "Respond with \"good\" or \"poor\" and a brief reason.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"lookup_sales_data\",\n",
    "        \"description\": \"Fetch historical data of sales for a product or category.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"analyzing_data\",\n",
    "        \"description\": \"Does a statistical analysis of the data available, giving an output in form of a summary of trends/patterns found for example.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"create_visualization\",\n",
    "        \"description\": \"Generates a visualization schema of the data processed according to the user's configuration.\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor, ConsoleSpanExporter\n",
    "from opentelemetry import trace\n",
    "\n",
    "# Añade exportador a consola para debug\n",
    "trace.get_tracer_provider().add_span_processor(\n",
    "    SimpleSpanProcessor(ConsoleSpanExporter())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_classify |██████████| 294/294 (100.0%) | ⏳ 02:18<00:00 |  2.12it/s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>explanation</th>\n",
       "      <th>exceptions</th>\n",
       "      <th>execution_status</th>\n",
       "      <th>execution_seconds</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>faa0113f472fb26a</th>\n",
       "      <td>NOT_PARSABLE</td>\n",
       "      <td>incorrect</td>\n",
       "      <td>[]</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>4.543704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522a99763361f627</th>\n",
       "      <td>NOT_PARSABLE</td>\n",
       "      <td>incorrect</td>\n",
       "      <td>[]</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>0.260752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193ea1de96a7e4f</th>\n",
       "      <td>NOT_PARSABLE</td>\n",
       "      <td>incorrect</td>\n",
       "      <td>[]</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>0.152858</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53a22c3a269b96d4</th>\n",
       "      <td>NOT_PARSABLE</td>\n",
       "      <td>incorrect</td>\n",
       "      <td>[]</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>0.153575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229a2f9084e4d308</th>\n",
       "      <td>NOT_PARSABLE</td>\n",
       "      <td>correct</td>\n",
       "      <td>[]</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>0.145374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         label explanation exceptions execution_status  \\\n",
       "context.span_id                                                          \n",
       "faa0113f472fb26a  NOT_PARSABLE   incorrect         []        COMPLETED   \n",
       "522a99763361f627  NOT_PARSABLE   incorrect         []        COMPLETED   \n",
       "5193ea1de96a7e4f  NOT_PARSABLE   incorrect         []        COMPLETED   \n",
       "53a22c3a269b96d4  NOT_PARSABLE   incorrect         []        COMPLETED   \n",
       "229a2f9084e4d308  NOT_PARSABLE     correct         []        COMPLETED   \n",
       "\n",
       "                  execution_seconds  score  \n",
       "context.span_id                             \n",
       "faa0113f472fb26a           4.543704      0  \n",
       "522a99763361f627           0.260752      0  \n",
       "5193ea1de96a7e4f           0.152858      0  \n",
       "53a22c3a269b96d4           0.153575      0  \n",
       "229a2f9084e4d308           0.145374      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "#model = completion(model='ollama_chat/llama2', api_base=\"http://localhost:11434\", stream=False)\n",
    "#model.reload_client = lambda: None\n",
    "##model.verbose_generation_info = lambda: \"\"\n",
    "#model._timeout = lambda: 0\n",
    "model = LiteLLMModel(model=\"ollama_chat/llama3.2:3B\")\n",
    "input_state = {\"prompt\": \"Show me sales in Nov 2021\"}\n",
    "#result = run_graph_with_tracing(input_state)\n",
    "#pprint.pprint(result)\n",
    "\n",
    "#verify traces\n",
    "\n",
    "tool_calls_df = px.Client().query_spans(decide_query, project_name=PROJECT_NAME, timeout=None)\n",
    "tool_calls_df = tool_calls_df.dropna(subset=[\"tool_call\"])\n",
    "\n",
    "tool_calls_df.head()\n",
    "\n",
    "tool_call_eval = llm_classify(\n",
    "    dataframe=tool_calls_df,\n",
    "    template=TOOL_CALLING_PROMPT_TEMPLATE.template[0].template.replace(\n",
    "        \"{tool_definitions}\", json.dumps(tools).replace(\"{\", '\"').replace(\"}\", '\"')),\n",
    "    rails=['correct', 'incorrect'],\n",
    "    model=model,\n",
    "    provide_explanation=True,\n",
    "    concurrency=1,\n",
    ")\n",
    "\n",
    "tool_call_eval['score'] = tool_call_eval.apply(lambda x: 1 if x['label']=='correct' else 0, axis=1)\n",
    "\n",
    "tool_call_eval.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(eval_name=\"Tool Calling Eval\", dataframe=tool_call_eval),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>query_gen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f336001a171b6854</th>\n",
       "      <td>What was the most popular product SKU?</td>\n",
       "      <td>SKU_Coded\\n0    6200700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca53fe2ff8052d77</th>\n",
       "      <td>What was the total revenue across all stores?</td>\n",
       "      <td>sum(Total_Sale_Value)\\n0           1.327264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87feb9c9d85bad98</th>\n",
       "      <td>Which store had the highest sales volume?</td>\n",
       "      <td>Store_Number\\n0          2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5f64e036ee56ba02</th>\n",
       "      <td>Which store had the highest sales volume?</td>\n",
       "      <td>Store_Number\\n0          2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8cb9cb04f90ddc6</th>\n",
       "      <td>Create a bar chart showing total sales by store</td>\n",
       "      <td>Store_Number  sum(Total_Sale_Value)\\n0    ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         question  \\\n",
       "context.span_id                                                     \n",
       "f336001a171b6854           What was the most popular product SKU?   \n",
       "ca53fe2ff8052d77    What was the total revenue across all stores?   \n",
       "87feb9c9d85bad98        Which store had the highest sales volume?   \n",
       "5f64e036ee56ba02        Which store had the highest sales volume?   \n",
       "b8cb9cb04f90ddc6  Create a bar chart showing total sales by store   \n",
       "\n",
       "                                                          query_gen  \n",
       "context.span_id                                                      \n",
       "f336001a171b6854                            SKU_Coded\\n0    6200700  \n",
       "ca53fe2ff8052d77     sum(Total_Sale_Value)\\n0           1.327264...  \n",
       "87feb9c9d85bad98                      Store_Number\\n0          2970  \n",
       "5f64e036ee56ba02                      Store_Number\\n0          2970  \n",
       "b8cb9cb04f90ddc6      Store_Number  sum(Total_Sale_Value)\\n0    ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_df = px.Client().query_spans(sql_query, project_name=PROJECT_NAME, timeout=None)\n",
    "sql_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>query_gen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f336001a171b6854</th>\n",
       "      <td>What was the most popular product SKU?</td>\n",
       "      <td>SKU_Coded\\n0    6200700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca53fe2ff8052d77</th>\n",
       "      <td>What was the total revenue across all stores?</td>\n",
       "      <td>sum(Total_Sale_Value)\\n0           1.327264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87feb9c9d85bad98</th>\n",
       "      <td>Which store had the highest sales volume?</td>\n",
       "      <td>Store_Number\\n0          2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5f64e036ee56ba02</th>\n",
       "      <td>Which store had the highest sales volume?</td>\n",
       "      <td>Store_Number\\n0          2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8cb9cb04f90ddc6</th>\n",
       "      <td>Create a bar chart showing total sales by store</td>\n",
       "      <td>Store_Number  sum(Total_Sale_Value)\\n0    ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         question  \\\n",
       "context.span_id                                                     \n",
       "f336001a171b6854           What was the most popular product SKU?   \n",
       "ca53fe2ff8052d77    What was the total revenue across all stores?   \n",
       "87feb9c9d85bad98        Which store had the highest sales volume?   \n",
       "5f64e036ee56ba02        Which store had the highest sales volume?   \n",
       "b8cb9cb04f90ddc6  Create a bar chart showing total sales by store   \n",
       "\n",
       "                                                          query_gen  \n",
       "context.span_id                                                      \n",
       "f336001a171b6854                            SKU_Coded\\n0    6200700  \n",
       "ca53fe2ff8052d77     sum(Total_Sale_Value)\\n0           1.327264...  \n",
       "87feb9c9d85bad98                      Store_Number\\n0          2970  \n",
       "5f64e036ee56ba02                      Store_Number\\n0          2970  \n",
       "b8cb9cb04f90ddc6      Store_Number  sum(Total_Sale_Value)\\n0    ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = (SpanQuery()\n",
    "    .where(\"name == 'sql_query_exec' and span_kind == 'TOOL'\")\n",
    ").select(\n",
    "    question=\"input.value\",\n",
    "    query_gen=\"output.value\",\n",
    ")\n",
    "query_df = px.Client().query_spans(query, project_name=PROJECT_NAME, timeout=None)\n",
    "query_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluator for the other tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_classify |██████████| 28/28 (100.0%) | ⏳ 00:14<00:00 |  1.93it/s\n"
     ]
    }
   ],
   "source": [
    "# === SQL Generation Evaluation ===\n",
    "\n",
    "sql_df = px.Client().query_spans(sql_query, project_name=PROJECT_NAME, timeout=None)\n",
    "#sql_df = sql_df[sql_df[\"question\"].str.contains(\"Generate an SQL query based on a prompt.\", na=False)]\n",
    "\n",
    "with suppress_tracing():\n",
    "    sql_eval = llm_classify(\n",
    "        dataframe=sql_df,\n",
    "        template=SQL_EVAL_GEN_PROMPT,\n",
    "        rails=[\"correct\", \"incorrect\"],\n",
    "        model=model,\n",
    "        provide_explanation=True\n",
    "    )\n",
    "\n",
    "sql_eval ['score'] = sql_eval.apply(lambda x: 1 if x['label']=='correct' else 0, axis=1)\n",
    "sql_eval.head()\n",
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(eval_name=\"SQL Generation Eval\", dataframe=sql_eval),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>query_gen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f336001a171b6854</th>\n",
       "      <td>What was the most popular product SKU?</td>\n",
       "      <td>SKU_Coded\\n0    6200700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca53fe2ff8052d77</th>\n",
       "      <td>What was the total revenue across all stores?</td>\n",
       "      <td>sum(Total_Sale_Value)\\n0           1.327264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87feb9c9d85bad98</th>\n",
       "      <td>Which store had the highest sales volume?</td>\n",
       "      <td>Store_Number\\n0          2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5f64e036ee56ba02</th>\n",
       "      <td>Which store had the highest sales volume?</td>\n",
       "      <td>Store_Number\\n0          2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8cb9cb04f90ddc6</th>\n",
       "      <td>Create a bar chart showing total sales by store</td>\n",
       "      <td>Store_Number  sum(Total_Sale_Value)\\n0    ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         question  \\\n",
       "context.span_id                                                     \n",
       "f336001a171b6854           What was the most popular product SKU?   \n",
       "ca53fe2ff8052d77    What was the total revenue across all stores?   \n",
       "87feb9c9d85bad98        Which store had the highest sales volume?   \n",
       "5f64e036ee56ba02        Which store had the highest sales volume?   \n",
       "b8cb9cb04f90ddc6  Create a bar chart showing total sales by store   \n",
       "\n",
       "                                                          query_gen  \n",
       "context.span_id                                                      \n",
       "f336001a171b6854                            SKU_Coded\\n0    6200700  \n",
       "ca53fe2ff8052d77     sum(Total_Sale_Value)\\n0           1.327264...  \n",
       "87feb9c9d85bad98                      Store_Number\\n0          2970  \n",
       "5f64e036ee56ba02                      Store_Number\\n0          2970  \n",
       "b8cb9cb04f90ddc6      Store_Number  sum(Total_Sale_Value)\\n0    ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_classify |██████████| 49/49 (100.0%) | ⏳ 02:43<00:00 |  3.34s/it\n"
     ]
    }
   ],
   "source": [
    "# === Data Analysis Evaluation ===\n",
    "clarity_df = px.Client().query_spans(analysis_query, project_name=PROJECT_NAME, timeout=None)\n",
    "clarity_df.head()\n",
    "with suppress_tracing():\n",
    "    clarity_eval = llm_classify(\n",
    "        dataframe=clarity_df,\n",
    "        template=CLARITY_LLM_JUDGE_PROMPT,\n",
    "        rails=[\"clear\", \"unclear\"],\n",
    "        model=model,\n",
    "        provide_explanation=True\n",
    "    )\n",
    "clarity_eval['score'] = clarity_eval.apply(lambda x: 1 if x['label']=='clear' else 0, axis=1)\n",
    "\n",
    "clarity_eval.head()\n",
    "\n",
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(eval_name=\"Response Clarity\", dataframe=clarity_eval),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Visualization Evaluation ===\n",
    "code_gen_df = px.Client().query_spans(viz_query, project_name=PROJECT_NAME, timeout=None)\n",
    "code_gen_df.head()\n",
    "\n",
    "def code_is_runnable(output:str) -> bool:\n",
    "    if not output or not isinstance(output, str):\n",
    "        return False  \n",
    "    \n",
    "    output = output.replace(\"```python\", \"\").replace(\"```\", \"\").strip()\n",
    "    \n",
    "    try:\n",
    "        exec(output, {}, {})  \n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "    \n",
    "code_gen_df['label'] = code_gen_df['generated_code'].apply(code_is_runnable).map({True: \"runnable\", False: \"not_runnable\"})\n",
    "code_gen_df['score'] = code_gen_df['label'].apply(lambda x: 1 if x=='runnable' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>generated_code</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7a6eeae56091e468</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>not_runnable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52b4a4e881162271</th>\n",
       "      <td>Show me the sales of Nov 2021</td>\n",
       "      <td>\\nimport matplotlib.pyplot as plt\\n\\ndef creat...</td>\n",
       "      <td>not_runnable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input  \\\n",
       "context.span_id                                   \n",
       "7a6eeae56091e468                           None   \n",
       "52b4a4e881162271  Show me the sales of Nov 2021   \n",
       "\n",
       "                                                     generated_code  \\\n",
       "context.span_id                                                       \n",
       "7a6eeae56091e468                                               None   \n",
       "52b4a4e881162271  \\nimport matplotlib.pyplot as plt\\n\\ndef creat...   \n",
       "\n",
       "                         label  score  \n",
       "context.span_id                        \n",
       "7a6eeae56091e468  not_runnable      0  \n",
       "52b4a4e881162271  not_runnable      0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_gen_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(eval_name=\"Runnable Code Eval\", dataframe=code_gen_df),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
